# Guide de d√©pannage

Solutions aux probl√®mes courants avec Better Robots.txt et configurations robots.txt.

## Probl√®mes fr√©quents

### 1. robots.txt ne se met pas √† jour

**Sympt√¥mes** :
- Les changements de param√®tres ne s'appliquent pas
- Ancien robots.txt toujours visible
- Modifications sauvegard√©es mais non effectives

**Causes possibles** :
```markdown
üîç **Cache WordPress** :
   - Cache de page activ√©
   - Plugin de cache actif
   - Cache serveur mis en place

üîç **Cache navigateur** :
   - Navigateur garde l'ancienne version
   - Fichier robots.txt mis en cache localement

üîç **CDN ou proxy** :
   - Cloudflare cache
   - Autre service CDN
   - Proxy inverse
```

**Solutions - √âtape par √©tape** :

1. **Videz tous les caches** :
   ```bash
   # Via WordPress admin
   - Allez dans Performance ‚Üí Purge Caches (si W3 Total Cache)
   - Ou R√©glages ‚Üí WP Rocket ‚Üí Vider le cache
   - Ou votre plugin de cache sp√©cifique

   # Via ligne de commande (si accessible)
   wp cache flush
   ```

2. **Videz le cache navigateur** :
   ```markdown
   - Ctrl+F5 (Windows/Linux)
   - Cmd+Shift+R (Mac)
   - Outils de d√©veloppement ‚Üí R√©seau ‚Üí Vider le cache
   - Navigation priv√©e pour tester
   ```

3. **Videz le cache CDN** :
   ```markdown
   - Cloudflare : Purge Everything
   - Autre CDN : Clear cache complet
   - Attendez 5-10 minutes pour propagation
   ```

4. **Testez avec diff√©rentes m√©thodes** :
   ```bash
   # Test curl
   curl -I https://votresite.com/robots.txt

   # Test avec user-agent sp√©cifique
   curl -A "Googlebot" https://votresite.com/robots.txt
   ```

### 2. Erreur 404 sur robots.txt

**Sympt√¥mes** :
- `https://votresite.com/robots.txt` renvoie 404
- Fichier robots.txt introuvable
- Moteurs de recherche ne peuvent pas acc√©der au fichier

**Causes possibles** :
```markdown
üîç **Configuration WordPress** :
   - "Discourager les moteurs de recherche" activ√©
   - Structure de permaliens cass√©e
   - Probl√®me de r√©√©criture d'URL

üîç **Permissions fichiers** :
   - Permissions incorrectes sur les r√©pertoires
   - Probl√®me de propri√©taire de fichiers
   - Restrictions d'acc√®s serveur

üîç **Fichier physique en conflit** :
   - Ancien fichier robots.txt physique existe
   - Override du serveur configur√©
   - Configuration Nginx/Apache en conflit
```

**Solutions d√©taill√©es** :

1. **V√©rifiez les param√®tres WordPress** :
   ```markdown
   ‚úÖ Allez dans R√©glages ‚Üí Lecture
   ‚úÖ D√©cochez "Discourager les moteurs de recherche..."
   ‚úÖ Sauvegardez les modifications
   ```

2. **V√©rifiez la structure des permaliens** :
   ```markdown
   ‚úÖ Allez dans R√©glages ‚Üí Permaliens
   ‚úÖ Cliquez "Sauvegarder les modifications"
   ‚úÖ Aucun changement n√©cessaire, juste sauvegardez
   ```

3. **V√©rifiez les permissions de fichiers** :
   ```bash
   # Permissions recommand√©es
   chmod 755 /var/www/html/
   chmod 755 /var/www/html/wp-content/
   chmod 644 /var/www/html/wp-content/plugins/

   # V√©rifiez si WordPress peut √©crire
   wp option get home
   wp option get siteurl
   ```

4. **Cherchez les fichiers robots.txt physiques** :
   ```bash
   # Trouvez tous les fichiers robots.txt
   find /var/www/html -name "robots.txt" -type f

   # S'il y en a un dans la racine, d√©placez-le ou supprimez-le
   mv /var/www/html/robots.txt /var/www/html/robots.txt.backup
   ```

### 3. R√®gles ne s'appliquent pas correctement

**Sympt√¥mes** :
- Pages cens√©es √™tre bloqu√©es accessibles
- Pages autoris√©es bloqu√©es par erreur
- Moteurs de recherche ignorent les r√®gles

**Diagnostique** :

1. **Testez avec Google Robots.txt Tester** :
   ```markdown
   üìä Allez dans Google Search Console
   üìä S√©lectionnez votre propri√©t√©
   üìä Outils d'exploration ‚Üí Tester robots.txt
   üìä Testez des URLs sp√©cifiques
   ```

2. **Analysez la syntaxe** :
   ```markdown
   ‚úÖ V√©rifiez la syntaxe robots.txt
   ‚úÖ Confirmez les chemins absolus
   ‚úÖ Validez les caract√®res g√©n√©riques
   ‚úÖ V√©rifiez l'ordre des r√®gles
   ```

3. **Testez avec diff√©rents user-agents** :
   ```bash
   # Test Googlebot
   curl -A "Googlebot" -I https://votresite.com/private-page/

   # Test Bingbot
   curl -A "Bingbot" -I https://votresite.com/private-page/

   # Test un user-agent g√©n√©rique
   curl -A "Mozilla/5.0" -I https://votresite.com/private-page/
   ```

### 4. Conflits avec d'autres plugins SEO

**Sympt√¥mes** :
- Plusieurs plugins essaient de g√©rer robots.txt
- Param√®tres √©cras√©s automatiquement
- Comportement impr√©visible

**Plugins souvent en conflit** :
```markdown
‚ö†Ô∏è **Yoast SEO** :
   - Options dans SEO ‚Üí Avanc√© ‚Üí Outils d'exploration
   - "Cr√©er un fichier robots.txt" peut √™tre activ√©

‚ö†Ô∏è **Rank Math** :
   - Configuration dans Rank Math ‚Üí Titres et m√©ta
   - Options de modification robots.txt disponibles

‚ö†Ô∏è **All in One SEO Pack** :
   - Options dans Outils d'exploration
   - Gestion robots.txt int√©gr√©e

‚ö†Ô∏è **Plugins robots.txt d√©di√©s** :
   - KB Robots.txt
   - Robots.txt Manager
   - Autres similaires
```

**Solution compl√®te** :

1. **Identifiez tous les plugins concern√©s** :
   ```markdown
   üìã Faites la liste des plugins install√©s
   üìã V√©rifiez les param√®tres robots.txt de chacun
   üìã Notez ceux qui ont des options robots.txt
   ```

2. **Choisissez un seul gestionnaire** :
   ```markdown
   ‚úÖ **Option A** : Utiliser seulement Better Robots.txt
   - D√©sactivez robots.txt dans tous les autres plugins
   - Configurez Better Robots.txt comme principal

   ‚úÖ **Option B** : Utiliser un autre plugin
   - D√©sactivez Better Robots.txt
   - Configurez l'autre plugin comme souhait√©
   ```

3. **Configurez les priorit√©s** :
   ```markdown
   üéØ Dans Better Robots.txt :
   - Utilisez le mode "Remplacer" si disponible
   - Activez la priorit√© sur autres plugins
   - Testez apr√®s configuration
   ```

### 5. Probl√®mes multisite

**Sympt√¥mes sp√©cifiques multisite** :
- R√®gles non appliqu√©es sur certains sous-sites
- Configuration r√©seau ne se propage pas
- Comportement incoh√©rent entre sites

**Diagnostique multisite** :

1. **V√©rifiez la configuration r√©seau** :
   ```markdown
   üîç Allez dans Tableau de bord ‚Üí R√©seau ‚Üí Param√®tres
   üîç V√©rifiez les param√®tres robots.txt r√©seau
   üîç Confirmez que "Better Robots.txt" est activ√© r√©seau
   ```

2. **Testez chaque sous-site individuellement** :
   ```bash
   # Test robots.txt pour chaque sous-site
   curl -I https://site1.votresite.com/robots.txt
   curl -I https://site2.votresite.com/robots.txt
   curl -I https://votresite.com/site1/robots.txt
   ```

3. **V√©rifiez les permissions multisite** :
   ```markdown
   ‚úÖ L'administrateur r√©seau a les droits n√©cessaires
   ‚úÖ Les administrateurs de site ont les permissions locales
   ‚úÖ Les r√®gles d'h√©ritage sont correctement configur√©es
   ```

## Outils de d√©pannage

### Tests automatis√©s

**Script de test complet** :
```bash
#!/bin/bash
# Script de test robots.txt

SITE_URL="https://votresite.com"
ROBOTS_URL="$SITE_URL/robots.txt"

echo "=== Test de base robots.txt ==="
curl -I "$ROBOTS_URL"

echo -e "\n=== Test avec diff√©rents user-agents ==="
# Test Googlebot
echo "Googlebot:"
curl -A "Googlebot" -I "$SITE_URL/wp-admin/"

# Test Bingbot
echo "Bingbot:"
curl -A "Bingbot" -I "$SITE_URL/wp-admin/"

# Test user-agent g√©n√©rique
echo "Generic:"
curl -A "Mozilla/5.0" -I "$SITE_URL/wp-admin/"

echo -e "\n=== Test de validation ==="
# V√©rifiez que le fichier est accessible
if curl -s "$ROBOTS_URL" | grep -q "User-agent"; then
    echo "‚úÖ robots.txt valide et accessible"
else
    echo "‚ùå robots.txt invalide ou inaccessible"
fi
```

### Outils en ligne

**Services de validation** :
```markdown
üîó **Google Search Console** :
   - Outils d'exploration ‚Üí Tester robots.txt
   - Analyse compl√®te des r√®gles
   - D√©tection d'erreurs

üîó **Bing Webmaster Tools** :
   - Outils ‚Üí Analyser robots.txt
   - Test des URLs sp√©cifiques
   - Rapports d√©taill√©s

üîó **Robots.txt Tester** (tools.robotstxt.org) :
   - Validation syntaxique
   - Test par user-agent
   - Analyse compl√®te
```

### Monitoring continu

**Scripts de surveillance** :
```php
<?php
// Script de surveillance robots.txt
function check_robotstxt_health() {
    $url = 'https://votresite.com/robots.txt';
    $response = wp_remote_get($url);

    if (is_wp_error($response)) {
        error_log('robots.txt inaccessible: ' . $response->get_error_message());
        return false;
    }

    $body = wp_remote_retrieve_body($response);
    if (!preg_match('/User-agent:\s*\*/i', $body)) {
        error_log('robots.txt format invalide');
        return false;
    }

    return true;
}

// Planifier une v√©rification quotidienne
if (!wp_next_scheduled('check_robotstxt_daily')) {
    wp_schedule_event(time(), 'daily', 'check_robotstxt_daily');
}

add_action('check_robotstxt_daily', 'check_robotstxt_health');
?>
```

## Solutions par type d'h√©bergement

### H√©bergement partag√©

**Probl√®mes courants** :
```markdown
‚ö†Ô∏è **Limitations de ressources** :
   - M√©moire PHP limit√©e
   - Temps d'ex√©cution restreint
   - Acc√®s syst√®me limit√©

‚ö†Ô∏è **Restrictions de fichiers** :
   - Permissions limit√©es
   - Possibilit√© de .htaccess restreinte
   - Configuration serveur partag√©e
```

**Solutions adapt√©es** :
```markdown
‚úÖ **Configuration optimis√©e** :
   - Utilisez le mode virtuel (pas de fichier physique)
   - Minimisez le nombre de r√®gles
   - Activez la mise en cache WordPress

‚úÖ **Communication avec l'h√©bergeur** :
   - V√©rifiez les limitations sp√©cifiques
   - Demandez si des restrictions robots.txt existent
   - Confirmez les permissions requises
```

### VPS/D√©di√©

**Avantages √† exploiter** :
```markdown
‚úÖ **Contr√¥le complet** :
   - Configuration Apache/Nginx personnalis√©e
   - Permissions compl√®tes
   - Scripts personnalis√©s possibles

‚úÖ **Performance** :
   - Mode physique recommand√©
   - Cache avanc√© disponible
   - Monitoring personnalis√©
```

**Configuration optimis√©e VPS** :
```markdown
üöÄ **Nginx configuration** :
   server {
       location = /robots.txt {
           try_files $uri $uri/ /index.php?$args;
       }
   }

üöÄ **Apache .htaccess** :
   <Files "robots.txt">
       Order Allow,Deny
       Allow from all
   </Files>

üöÄ **Script de monitoring** :
   # Surveillance continue disponible
```

### Cloud/AWS

**Consid√©rations sp√©cifiques** :
```markdown
‚òÅÔ∏è **Load balancing** :
   - Assurez la coh√©rence entre serveurs
   - Utilisez le mode physique
   - Configuez les caches partag√©s

‚òÅÔ∏è **CDN integration** :
   - Mettez en cache robots.txt sur CDN
   - Configurez l'invalidation automatique
   - Optimisez les en-t√™tes Cache-Control
```

## Pr√©vention et maintenance

### Checklist de maintenance mensuelle

```markdown
‚úÖ **V√©rifications mensuelles** :
   - Validez le fichier robots.txt
   - Testez les pages importantes
   - V√©rifiez les sitemaps
   - Analysez les logs serveur
   - Surveillez les m√©triques SEO

‚úÖ **Mises √† jour r√©guli√®res** :
   - Mettez √† jour les listes de bots
   - R√©visez les r√®gles de blocage
   - Optimisez pour le nouveau contenu
   - Documentez les changements

‚úÖ **Tests de performance** :
   - V√©rifiez le temps de r√©ponse
   - Testez diff√©rents user-agents
   - Validez la compatibilit√© mobile
   - Confirmez l'accessibilit√© CDN
```

### Surveillance proactive

**Alertes automatiques** :
```php
<?php
// Configuration d'alertes
function setup_robotstxt_monitoring() {
    // V√©rification quotidienne
    wp_schedule_event(time(), 'daily', 'robotstxt_health_check');

    // Rapport hebdomadaire
    wp_schedule_event(time(), 'weekly', 'robotstxt_performance_report');
}

add_action('robotstxt_health_check', 'check_robotstxt_health');
add_action('robotstxt_performance_report', 'generate_robotstxt_report');
?>
```

---

**Besoin d'aide suppl√©mentaire ?**
- [Support communautaire](https://wordpress.org/support/plugin/better-robots-txt/)
- [Support premium](https://better-robots.com/support)
- [Documentation compl√®te](/fr/)