# Guide des param√®tres

Guide complet de tous les param√®tres et options de configuration de Better Robots.txt.

## Aper√ßu des param√®tres

Better Robots.txt fournit des param√®tres complets organis√©s en sections logiques :

- **Param√®tres de base** : Configuration robots.txt principale
- **Gestion des bots** : Contr√¥le quels bots peuvent acc√©der √† votre site
- **Int√©gration SEO** : Sitemap et optimisation des moteurs de recherche
- **Options avanc√©es** : R√®gles personnalis√©es et fonctionnalit√©s sp√©cialis√©es
- **E-commerce** : Optimisations sp√©cifiques √† WooCommerce

## Param√®tres de base

### 1. R√®gles par d√©faut

**Emplacement** : Param√®tres ‚Üí Configuration de base

Ce sont les r√®gles fondamentales appliqu√©es √† tous les fichiers robots.txt :

```txt
User-agent: *
Allow: /wp-admin/admin-ajax.php
Allow: /*/*.css
Allow: /*/*.js
Disallow: /wp-admin/
Disallow: /wp-includes/
Disallow: /readme.html
Disallow: /license.txt
Disallow: /xmlrpc.php
Disallow: /wp-login.php
Disallow: /wp-register.php
Disallow: */disclaimer/*
Disallow: *?attachment_id=
Disallow: /privacy-policy
```

**Ce que font ces r√®gles** :
- ‚úÖ **Allow** : Fonctionnalit√©s et ressources WordPress essentielles
- ‚ùå **Disallow** : Zones d'administration, fichiers sensibles et contenu dupliqu√©

### 2. User-agents personnalis√©s

**Emplacement** : Param√®tres ‚Üí R√®gles personnalis√©es

Ajoutez vos propres r√®gles robots.txt en utilisant la zone de texte :

**Format** :
```txt
User-agent: Googlebot
Allow: /special-content/
Disallow: /private/

User-agent: Bingbot
Crawl-delay: 1
```

**User-agents courants** :
- `Googlebot` : Robot Google
- `Bingbot` : Robot Bing
- `Slurp` : Robot Yahoo
- `DuckDuckBot` : Robot DuckDuckGo

### 3. Mode fichier

**Options** :
- **Virtuel (Gratuit)** : G√©n√©r√© √† la vol√©e
- **Physique (Pro)** : Fichier r√©el cr√©√©

**Recommandation** : Utilisez le mode virtuel pour la plupart des sites.

## Gestion des bots

### 1. Contr√¥le des bots principaux

**Emplacement** : Param√®tres ‚Üí Gestion des bots

**Moteurs de recherche autoris√©s par d√©faut** :
```markdown
‚úÖ Googlebot : google.com/bot.html
‚úÖ Bingbot : bing.com/bingbot.htm
‚úÖ Slurp : help.yahoo.com/help/us/ysearch/slurp
‚úÖ DuckDuckBot : duckduckgo.com/duckduckbot.html
```

### 2. Blocage des mauvais bots (Pro)

**Bots bloqu√©s automatiquement** :
```markdown
üö´ Scrapers de contenu
üö´ Harvesters d'e-mails
üö´ Outils de copie de site
üö´ Bots de spam SEO
üö´ Outils d'analyse concurrentielle
```

**Mise √† jour automatique** : La liste est maintenue par notre √©quipe et mise √† jour r√©guli√®rement.

### 3. Protection ChatGPT

**Options** :
```markdown
ü§ñ Bloquer : Emp√™che l'entra√Ænement IA
ü§ñ Autoriser : Permet l'indexation par l'IA
ü§ñ Personnalis√© : R√®gles sp√©cifiques par user-agent
```

## Int√©gration SEO

### 1. Param√®tres de sitemap

**Emplacement** : Param√®tres ‚Üí Int√©gration SEO

**D√©tection automatique** :
- **Yoast SEO** : D√©tection automatique du sitemap
- **Rank Math** : Int√©gration transparente
- **All in One SEO** : Support complet
- **Sitemap personnalis√©** : URL personnalis√©e

**Format de sortie** :
```txt
Sitemap: https://votresite.com/sitemap.xml
Sitemap: https://votresite.com/sitemap_index.xml
```

### 2. Optimisation du budget d'exploration

**Strat√©gies** :
- **Priorisation du contenu** : Pages importantes en premier
- **R√©duction du gaspillage** : Bloque les pages sans valeur
- **Optimisation de vitesse** : Exploration plus rapide
- **Indexation intelligente** : Meilleure d√©couverte

### 3. Directives SEO avanc√©es

**Options disponibles** :
```txt
Crawl-delay: 1          # D√©lai entre les requ√™tes
Request-rate: 1/5s      # Taux de requ√™tes maximum
Disallow: /*?*          # Bloquer les URLs avec param√®tres
Allow: /*.html$         # Autoriser seulement les fichiers HTML
```

## Options avanc√©es

### 1. R√®gles personnalis√©es

**Emplacement** : Param√®tres ‚Üí R√®gles personnalis√©es

**Syntaxe support√©e** :
```txt
# User-agent sp√©cifique
User-agent: Googlebot
Disallow: /private/

# Directives Allow/Disallow
Allow: /wp-content/uploads/
Disallow: /wp-content/plugins/

# Caract√®res g√©n√©riques
Disallow: /*.pdf$
Disallow: /temp/*/

# Crawl-delay
User-agent: *
Crawl-delay: 1
```

### 2. Variables dynamiques

**Variables disponibles** :
- `%SITE_URL%` : URL de votre site
- `%UPLOAD_DIR%` : R√©pertoire d'upload
- `%THEME_DIR%` : R√©pertoire du th√®me
- `%PLUGIN_DIR%` : R√©pertoire des plugins

**Exemple** :
```txt
Allow: %UPLOAD_DIR%/
Disallow: %PLUGIN_DIR%/
```

### 3. Tests et validation

**Outils int√©gr√©s** :
- **Validateur de syntaxe** : V√©rifie les erreurs
- **Testeur de r√®gles** : Simule le comportement des bots
- **Analyseur d'impact** : √âvalue les changements
- **Rapport de sant√©** : Score de configuration

## Param√®tres e-commerce

### 1. Optimisation WooCommerce

**Emplacement** : Param√®tres ‚Üí E-commerce

**URLs bloqu√©es par d√©faut** :
```txt
# Panier et paiement
Disallow: /cart/
Disallow: /checkout/
Disallow: /my-account/
Disallow: /add-to-cart/

# Pages de compte
Disallow: /lost-password/
Disallow: /customer-logout/
Disallow: /order-received/

# Param√®tres de produits
Disallow: /*?add-to-cart=*
Disallow: /*?remove_item=*
Disallow: /*?quantity=*
```

**URLs autoris√©es** :
```txt
# Contenu important
Allow: /shop/
Allow: /product-category/
Allow: /products/
Allow: /*product*
```

### 2. Protection des donn√©es clients

**S√©curit√© renforc√©e** :
- **Chiffrement** : Protection des donn√©es sensibles
- **Masquage** : Cache les informations personnelles
- **Journalisation** : Suivi des acc√®s suspects
- **Alertes** : Notifications de s√©curit√©

### 3. Optimisation des performances

**Am√©liorations** :
- **R√©duction de la charge** : Moins de requ√™tes inutiles
- **Mise en cache** : R√©ponses mises en cache
- **CDN** : Int√©gration avec les r√©seaux de distribution
- **HTTP/2** : Support des derniers protocoles

## Param√®tres multisite

### 1. Gestion r√©seau

**Emplacement** : Param√®tres ‚Üí Multisite

**Options de contr√¥le** :
- **Centralis√©** : Une configuration pour tous les sites
- **Par site** : Configurations individuelles
- **Hybride** : R√®gles globales + sp√©cifiques

### 2. H√©ritage des r√®gles

**Priorit√© des r√®gles** :
1. **R√®gles du site** : Priorit√© la plus √©lev√©e
2. **R√®gles r√©seau** : Appliqu√©es si pas de surcharge
3. **R√®gles par d√©faut** : Fallback de s√©curit√©

### 3. D√©ploiement en masse

**Fonctionnalit√©s** :
- **Application group√©e** : Mettez √† jour plusieurs sites
- **Mod√®les** : Appliquez des configurations pr√©d√©finies
- **Tests** : Validation avant d√©ploiement
- **Restauration** : Retour en arri√®re automatique

## Bonnes pratiques de configuration

### 1. S√©curit√©

**R√®gles essentielles** :
```txt
# Toujours bloquer ces zones
Disallow: /wp-admin/
Disallow: /wp-includes/
Disallow: /wp-config.php
Disallow: /.htaccess

# Prot√©ger les donn√©es sensibles
Disallow: /private/
Disallow: /confidential/
Disallow: /*?secret=*
```

### 2. Performance

**Optimisations recommand√©es** :
```txt
# R√©duire le gaspillage de budget
Disallow: */page/*
Disallow: */tag/
Disallow: */search/

# Contr√¥ler le taux d'exploration
Crawl-delay: 1
Request-rate: 1/5s
```

### 3. SEO

**Directives optimales** :
```txt
# Assurer l'indexation du contenu important
Allow: /wp-content/uploads/
Allow: /*.jpg$
Allow: /*.png$
Allow: /*.html$

# R√©f√©rencer les sitemaps
Sitemap: https://votresite.com/sitemap.xml
```

## D√©pannage des param√®tres

### Probl√®mes courants

#### robots.txt ne se met pas √† jour
1. Videz tous les caches
2. V√©rifiez les permissions de fichiers
3. Testez avec diff√©rents user-agents

#### R√®gles non appliqu√©es
1. V√©rifiez la syntaxe
2. Testez avec l'outil de validation
3. Confirmez l'ordre de priorit√©

#### Conflits avec d'autres plugins
1. D√©sactivez les autres plugins robots.txt
2. V√©rifiez les param√®tres SEO des plugins
3. Utilisez le mode de remplacement

### Outils de test

**Test manuel** :
```bash
curl -A "Googlebot" https://votresite.com/robots.txt
curl -A "Bingbot" -I https://votresite.com/limited-page/
```

**Outils en ligne** :
- Google Search Console
- Bing Webmaster Tools
- Robots.txt Tester
- Screaming Frog

## Sauvegarde et restauration

### 1. Sauvegarde automatique

**Options** :
- **Quotidienne** : Sauvegarde quotidienne des param√®tres
- **Avant modification** : Sauvegarde avant chaque changement
- **Versioning** : Conservation des versions pr√©c√©dentes

### 2. Export/Import

**Formats support√©s** :
- **JSON** : Param√®tres complets
- **TXT** : R√®gles robots.txt uniquement
- **CSV** : Liste des user-agents et r√®gles

### 3. Restauration

**Options de r√©cup√©ration** :
- **Derni√®re sauvegarde** : Restauration rapide
- **Point dans le temps** : S√©lection d'une date sp√©cifique
- **R√©initialisation** : Retour aux param√®tres par d√©faut

---

**Besoin d'aide ?** Consultez notre [Guide de d√©pannage](/fr/troubleshooting) ou contactez notre support premium.